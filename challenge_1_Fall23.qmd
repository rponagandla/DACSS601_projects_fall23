---
title: "Challenge_1: Data Import, Description, and Transformation(1)"
author: "Rachana Ponagandla"
description: ""
date: "09/20/2023"
format:
  html:
    df-print: paged
    css: "styles.css"
    embed-resources: true
    self-contained-math: true
categories:
  - weekly_challenges
  - challenge_1
---

**Make sure you change the author's name in the above YAML header.**

## Setup

If you have not installed the following packages, please install them before loading them.

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(haven) #for loading other datafiles (SAS, STATA, SPSS, etc.)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

This first weekly challenge aims to practice the following skill sets: 1. Read datasets in different file types; 2. Describe the datasets; 3. Exploring a few basic functions of data transformation and wrangling and present some descriptive statistics (such as min, max, and median).

There will be coding components (reading datasets and data transformation) and writing components (describing the datasets and some statistical information). Please read the instructions for each part and complete your challenges.

## Create your R quarto project and submit the standalone .html file.

This will be demonstrated in Sep 20 and 21 lab meetings.

## Datasets

There are four datasets provided in this challenge. Please download the following dataset files from Canvas or Google Classroom and save them to a folder within your project working directory (i.e.: "yourworkingdiectory_data"). If you don't have a folder to store the datasets, please create one.

-   babynames.csv (Required) ⭐
-   ESS_5.dta (Option 1) ⭐
-   p5v2018.sav (Option 2)⭐
-   railroad.xlsx (Required)⭐⭐

Find the `_data` folder, then use the correct R command to read the datasets.

## Part 1(Required). The Baby Names Dataset

1.  **Read the dataset "babynames.csv":**

```{r}
#Type your code here
babynames <- read.csv("_data/babynames.csv")
```

2.  **Data Description: Please use the necessary commands and codes and briefly describe this data with a short writing paragraph answering the following questions.**

The babynames.csv dataset contains columns "Name, Sex, Occurences and Year". It contains the records of baby names, their gender and occurences of specific baby name in an year.

```{r}
#Type your code here; and write a paragraph answering the questions.
head(babynames)
```

```         
\(1\) What is the dimension of the data (# of rows and columns)?

The dimension of the data is 
Number of rows = 2084710
Number of columns = 4
```

```{r}
dim(babynames)
```

```         
\(2\) What do the rows and columns mean in this data?
```

```{r}
colnames(babynames)
```

```         
Rows:

Each row in the dataset represents unique combination of baby name, gender associated with that name, number of occurences of that name with that specific gender in that specific year, and the year.

Columns:
Name-> represents the name of the baby
Sex-> represents the gender associated with the baby name
Occurences -> Indicates the number of occurences of particular baby name with a specific gender in a specific year
Year -> represents the year when that specific baby name was recorded

\(3\) What is the unit of observation? In other words, what does each case mean in this data?

The unit of observation in this dataset is a unique combination of a baby name, the sex associated with that name, and the year. Each case or row in the dataset represents the count of a specific baby name for a particular gender in a given year.

\(4\) According to the lecture, is this a "tidy" data?

Yes, this is a "tidy" data because the columns in the dataset (Name, Sex, Occurrences, Year) each represent a variable. Each row is an observation because each row in the dataset represents a unique combination of a baby name, the gender associated with that name, and the year and also each observation in the dataset does have specific data points/entries for each variable. The data is ready to analyze and visualize.
```

3.  **Data Transformation: use necessary commands and codes and answer the following questions.**

    \(1\) How many unique male names, unique female names, and total unique names are in the data?

    Number of unique male names: 43653, Number of unique female names: 70225, Number of total unique names: 102447

    ```{r}
    # Count unique male and female names
    male_names <- unique(babynames[babynames$Sex == "Male", ]$Name)
    female_names <- unique(babynames[babynames$Sex == "Female", ]$Name)

    # Count total unique names
    total_unique_names <- unique(babynames$Name)

    # Number of unique names
    num_male_names <- length(male_names)
    num_female_names <- length(female_names)
    num_total_unique_names <- length(total_unique_names)

    # Print the results
    cat("Number of unique male names:", num_male_names, "\n")
    cat("Number of unique female names:", num_female_names, "\n")
    cat("Total number of unique names:", num_total_unique_names, "\n")

    ```

```         
\(2\) How many years of names does this data record?

Number of years of names this data recorded: 143
```

```{r}
unique_years <- unique(babynames$Year)
num_unique_years <- length(unique_years)
cat("Number of unique years in the data:", num_unique_years, "\n")

```

```         
\(3\) Summarize the min, mean, median, and max of "Occurrence". (Must use summarize())

min: 5
mean: 175.2112
median: 12
max: 99693
```

```{r}
summary_occurrences <- babynames %>%
  summarize(
    min_occurrence = min(Occurrences),
    mean_occurrence = mean(Occurrences),
    median_occurrence = median(Occurrences),
    max_occurrence = max(Occurrences)
  )

print(summary_occurrences)

```

```         
\(4\) (Optional) Summarize the min, mean, median, and max of "Occurrence" by decade.
```

```{r}
summary_by_decade <- babynames %>% 
  mutate(decade = floor(Year/10)*10) %>% 
  group_by(decade) %>% 
  summarize(
    min_occurrence = min(Occurrences),
    mean_occurrence = mean(Occurrences),
    median_occurrence = median(Occurrences),
    max_occurrence = max(Occurrences)
  )
print(summary_by_decade)
```

## Part 2. Choose One Option of Tasks to Complete

**In this part, please choose either of the two datasets to complete the tasks.**

## Optional 1: The European Social Survey Dataset

The European Social Survey (ESS) is an academically-driven multi-country survey, which has been administered in over 30 countries to date. Its three aims are, firstly - to monitor and interpret changing public attitudes and values within Europe and to investigate how they interact with Europe's changing institutions, secondly - to advance and consolidate improved methods of cross-national survey measurement in Europe and beyond, and thirdly - to develop a series of European social indicators, including attitudinal indicators.

In the fifth round, the survey covers 28 countries and investigates two major topics: Family Work and Wellbeing and Justice.

1.  **Read the dataset "ESS_5.dta".**

    ```{r}
    #Type your code here
    ess_5 <- read_dta("_data/ESS_5.dta")
    head(ess_5)
    ```

<!-- -->

2.  **Data Description: Please use the necessary commands and codes and briefly describe this data with a short writing paragraph answering the following questions.**

    \(1\) What is the dimension of the data (# of rows and columns)?

    Number of rows: 52458

    Number of columns: 696

    ```{r}
    #Type your code here; and write a paragraph answering the questions.
    dim(ess_5)
    ```

    As we can see, this data is very large. We don't want to study the whole data. Let's just reload the following selected columns: "idno, essroud, male, age, edu, income_10, eth_major, media (a standardized measure of the frequency of media consumption), and cntry".

    ```{r}
    #Type your code here; and write a paragraph answering the questions.
    ess_5_reloaded <- ess_5 %>%
      select(idno, essround, male, age, edu, income_10, eth_major, media, cntry)
    dim(ess_5_reloaded)

    ```

    \(2\) For the reloaded data, what do the rows and columns mean in this data?

```{r}
colnames(ess_5_reloaded)
```

```         
The rows represent individual respondents from various countries who participated in the European Social Survey's fifth round and the columns represent different attributes collected in the survey.
Columns:
idno: ID number of the respondent
essround: The round of the ESS that the data was collected in
male: A binary variable indicating the gender of the respondent
age: The age of the respondent
edu: The education level of the respondent
income_10: The income decile of the respondent
eth_major: Whether the respondent belongs to the ethnic majority in their country
media: A standardized measure of the frequency of media consumption
cntry: The country of the respondent

\(3\) What is the unit of observation? In other words, what does each case mean in this data?
The unit of observation in this dataset is an individual respondent. Each case in the data represents a single respondent who participated in the European Social Survey's fifth round. For each respondent, the data captures their unique ID, the survey round, their gender, age, education level, income decile, ethnicity, their standardized frequency of media consumption, and the country they are from. 

\(4\) According to the lecture, is this a "tidy" data?

Yes, this is a "tidy" data because the columns in the reloaded dataset ("idno", "essround","male", "age", "edu", "income_10","eth_major","media","cntry") each represent a variable. Each row corresponds to a distinct observation because each row represents unique data based on the "idno". Also each observation in the dataset does have specific data points/entries for each variable. Even if some of those entries are "NA", dataset is still tidy.
```

3.  **Data Transformation: use necessary commands and codes and answer the following questions.**

    \(1\) How many unique countries are in the data?

    Number of unique countries: 27

```{r}
unique_countries <- length(unique(ess_5_reloaded$cntry))
cat("Number of unique countries:", unique_countries)

```

```         
\(2\) What are the range and average of the following variables: "age", "edu", and "media"? Must use summarize().

age:
  min: 14
  max: 101
  average: 47.91529
edu:
  min: 1
  max: 4
  average: 2.767531
media:
  min: 0
  max: 1
  average: 0.4786802
```

```{r}
summary_data <- ess_5_reloaded %>%
  summarize(
    min_age = min(age, na.rm = TRUE),
    max_age = max(age, na.rm = TRUE),
    mean_age = mean(age, na.rm = TRUE),
    
    min_edu = min(edu, na.rm = TRUE),
    max_edu = max(edu, na.rm = TRUE),
    mean_edu = mean(edu, na.rm = TRUE),
    
    min_media = min(media, na.rm = TRUE),
    max_media = max(media, na.rm = TRUE),
    mean_media = mean(media, na.rm = TRUE)
  )

print(summary_data)


```

```         
\(3\) How many missing data (NA) are in the following variables: "eth_major" and "income_10"? (tips: use is.na())

missing data:
  eth_major: 1310
  income_10: 12620
```

```{r}
missing_data <- ess_5_reloaded %>%
  summarize(
    missing_eth_major = sum(is.na(eth_major)),
    missing_income_10 = sum(is.na(income_10))
  )

print(missing_data)

```

## Optional 2: Polity V Data

The Polity data series is a data series in political science research. Polity is among prominent datasets that measure democracy and autocracy. The Polity5 dataset covers all major, independent states in the global system over the period 1800-2018 (i.e., states with a total population of 500,000 or more in the most recent year; currently 167 countries with Polity5 refinements completed for about half those countries).

1.  **Read the dataset "p5v2018.sav".**

    ```{r}
    #Type your code here
    ```

<!-- -->

2.  **Data Description: Please use the necessary commands and codes and briefly describe this data with a short writing paragraph answering the following questions.**

    ```{r}
    #Type your code here; and write a paragraph answering the questions.
    ```

    \(1\) What is the dimension of the data (# of rows and columns)?

    As we can see, this data contains many columns. We don't want to study the whole data. Let's keep the first seven columns and the ninth and ten columns.

    ```{r}
    #Type your code here; and write a paragraph answering the questions.
    ```

    \(2\) For the reloaded data, what do the rows mean in this data? What do the columns (#2-#8) mean? (If you have questions, check out [p.11-16 of the User Manual/Codebook of the dataset](https://www.systemicpeace.org/inscr/p5manualv2018.pdf)).

    \(3\) What is the unit of observation? In other words, what does each case mean in this data?

    \(4\) According to the lecture, is this a "tidy" data?

3.  **Data Transformation: use necessary commands and codes and answer the following questions.**

    ```{r}
    #Type your code here; and write a paragraph answering the questions.
    ```

    \(1\) How many unique countries are in the data?

    \(2\) How many years does this data record?

    \(3\) What are the range and average of the following variables: "democ" and "autoc"?

    \*\* Noted that in this data, negative integers (-88, -77, and -66) represent special cases. You should exclude them when calculating the range, average, and NAs.

    \(4\) How many missing data (NA) are in the following variables: "democ" and "autoc"? (tips: use is.na())

## Part 3. The Railroad Employee Data

1.  **Read the dataset "railroads.xls".**

    Many government organizations still use Excel spreadsheets to store data. This railroad dataset, published by the Railroad Retirement Board, is a typical example. It records the number of employees in each county and state in 2012.

    **Please load the data in R in a clean manner. You can start by doing the following things step by step.**

    \(1\) Read the first sheet of the Excel file;

    \(2\) Skipping the title rows;

    \(3\) Removing empty columns

    \(4\) Filtering "total" rows

    \(5\) Remove the table notes (the last two rows)

    ```{r}
    #Type your code here
    library(readxl)

    # The sheet contains 3 title rows, so skipping them
    railroad_data <- read_excel("_data/railroads.xls", sheet = 1, skip=3)
    railroad_data <- railroad_data[!apply(is.na(railroad_data) | railroad_data == "", 1, all),]
    railroad_data <- railroad_data[, colSums(is.na(railroad_data)) != nrow(railroad_data)]
    railroad_data <- railroad_data[!grepl("Total", railroad_data$STATE, ignore.case = TRUE), ]
    railroad_data <- railroad_data[-(nrow(railroad_data)-1): -nrow(railroad_data), ]
    head(railroad_data)
    ```

<!-- -->

2.  **Data Description: Please use the necessary commands and codes and briefly describe this data with a short writing paragraph answering the following questions.**

    ```{r}
    #Type your code here; and write a paragraph answering the questions.
    head(railroad_data)
    ```

    \(1\) What is the dimension of the data (# of rows and columns)?

    Number of rows: 2931 Number of columns: 3

```{r}
dim(railroad_data)
```

```         
\(2\) What do the rows and columns mean?

  Each row in the dataset represents individual records for each combination of STATE and COUNTY and the the number of employees in each county and state.
  
  Columns:
   STATE: Represents abbrevation for the state
   COUNTY: Represents name of the county with in the state
   TOTAL: Represents the total number of employees in the corresponding county of a specific state
```

```{r}
colnames(railroad_data)
```

```         
\(3\) What is the unit of observation? In other words, what does each case mean in this data?

The unit of observation in this dataset is the combination of a specific STATE and COUNTY. Each row in the dataset represents the count of railroad employees for a particular county within a specific state.


\(4\) According to the lecture, is this a "tidy" data?

Yes, this is a "tidy" data because it meets all three principles.
The columns in the dataset (STATE, COUNTY, TOTAL) each represent a variable. Each row is an observation because each row represents the number of employees for a specific county in a particular state and also each observation in the dataset does have specific data points/entries for each variable.
```

3.  **Data Transformation: use necessary commands and codes and answer the following questions.**

    \(1\) How many unique counties and states are in the data? (tips: you can try using the across() function to do an operation on two columns at the same time)

    Number of unique counties: 1710

    Number of unique states: 54

```{r}

unique_values <- railroad_data %>%
  summarise(across(c(STATE, COUNTY), ~length(unique(.x)), .names = "unique_{.col}"))

print(unique_values)


```

```         
\(2\) What is the total number of employees (total_employees) in this data?

Total number of employees: 256094
```

```{r}
total_employees <- sum(railroad_data$TOTAL, na.rm = TRUE)
cat("Total number of employees:",total_employees)

```

```         
\(3\) What are the min, max, mean, and median of "total_employees"

min: 1
max: 8207
mean: 87.37427
median: 21
```

```{r}
summary_stats <- railroad_data %>%
  summarise(
    min = min(TOTAL, na.rm = TRUE),
    max = max(TOTAL, na.rm = TRUE),
    mean = mean(TOTAL, na.rm = TRUE),
    median = median(TOTAL, na.rm = TRUE)
  )
print(summary_stats)

```

```         
\(4\) Which states have the most employees? And which countries have the most employees? (tips: use group_by() and arrange())

The state with most employees is TX
The top 5 states which has most employees are TX, IL, NY, NE, CA
```

```{r}
n <- 5 # or however many top states you want

top_states <- railroad_data %>%
  group_by(STATE) %>%
  summarise(total_state_employees = sum(TOTAL, na.rm = TRUE)) %>%
  arrange(-total_state_employees) %>%
  head(n)

print(top_states)

```

The county with most employees is COOK The top 5 counties with most employees are COOK, TARRANT, DOUGLAS, SUFFOLK, INDEPENDENT CITY

```{r}
n <- 5 # or however many top counties you want

top_counties <- railroad_data %>%
  group_by(STATE, COUNTY) %>%
  summarise(total_county_employees = sum(TOTAL, na.rm = TRUE)) %>%
  arrange(-total_county_employees) %>%
  head(n)

print(top_counties)

```
