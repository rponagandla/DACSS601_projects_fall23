---
title: "Challenge_3: Joining Relational Data, Writing Your Own Functions, and String Operations"
author: "Rachana Ponagandla"
description: ""
date: "10/4/2023"
format:
  html:
    df-print: paged
    css: "styles.css"
    embed-resources: true
    self-contained-math: true
categories:
  - weekly_challenges
  - challenge_3
---

**Make sure you change the author's name in the above YAML header.**

## Setup

If you have not installed the following packages, please install them before loading them.

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(readxl)
library(haven) #for loading other datafiles (SAS, STATA, SPSS, etc.)
library(stringr) # if you have not installed this package, please install it.
library(lubridate)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

In this challenge, we will practice `join()` with relational data. We will also explore some string functions to process, extract information, and mutate and clean data.

There will be coding components and writing components. Please read the instructions for each part and complete your challenges.

## Datasets

There are four datasets provided in this challenge. Please download the following dataset files from Canvas or Google Classroom and save them to a folder within your project working directory (i.e.: "yourworkingdiectory_data"). If you don't have a folder to store the datasets, please create one.

-   Part 1 and 2: ESS_5.dta and p5v2018.sav (used in Challenge#1) ⭐⭐
-   Part 3: babynames.csv (used in Challenge#1) ⭐
-   Part 4: australian_marriage_law_postal_survey_2017\_-\_response_final.xls ⭐⭐⭐

Find the `_data` folder, then use the correct R command to read the datasets.

## Part 1. Joining Individual-level and Country-Level Data

We have been working with these two datasets in the previous two challenges and should be familiar with one. Suppose we have a research project that studies European citizens' social behaviors and public opinions, and we are interested in how the countries that respondents live in influence their behavior and opinion. In this case, we will need to combine the two data for future analysis.

1.  **Read the two raw datasets.**

    **For ESS_5: (1) keep only the following columns:** *idno, essround, male, age, edu, eth_major, income_10, cntry, vote**.*** **(2)** recode *essround* to 2010, and rename it as *year*.

    **For Polity V, keep the first 10 columns.**

```{r}
#For ESS_5

ESS_5 <- read_dta("_data/ESS_5.dta")

ESS_5 <- ESS_5 %>% select(idno, essround, male, age, edu, eth_major, income_10, cntry, vote)

ESS_5 <- ESS_5 %>%
  mutate(essround = 2010) %>%
  rename(year = essround)

head(ESS_5)

# For Polity V
Polity_V <- read_spss("_data/p5v2018.sav")

Polity_V <- Polity_V[,1:10]

head(Polity_V)
```

2.  **Answer the following questions:**

    \(1\) In this project, which is the primary data, and which is the foreign data?

    Primary data is ESS_5 dataset as it has individual-level information about European Citizens behaviors and opinions such as gender, age, education level, and voting behavior. Foreign data is Polity V dataset because it has additional information about the countries present in primary data

    \(2\) What is(are) the key(s) for the two data?

    In ESS_5 dataset, combination of 'idno' and 'cntry' columns is the key

    In Polity V dataset, combination 'country' and 'year' columns together is the key or we can directly use the cyear column as the key as it is the combination of country and year

3.  **Suppose we have a theory that a country's level of democracy (*democ* in Polity V) affects an individual's electoral participation (*vote* in ESS 5). We must first conduct some necessary data transformation before merging the two data.**

    \(1\) Countries in ESS_5 are coded with their 2-digit codes (ISO-3166-1) in the *cntry* column. It is difficult to identify from these two-letter abbreviations. Let's first transform the *cntry* column by changing it from the abbreviations to the full country names and renaming the column as *country.*

    Please refer to [this website](https://datahub.io/core/country-list) for the list of countries with their 2-letter abbreviations. There are two ways to accomplish this task, and you can choose either one:

    a.  manually recode each country abbreviation to its full name or

    b.  download the [country list (csv) file](https://datahub.io/core/country-list/r/data.csv) from the above website, import it in RStudio, and merge it with the ESS_5 data. By doing so, you automatically join a new "country" column to the existing ESS_5 data.

    ```{r}

    country_list <- read_csv("./_data/country_list.csv", show_col_types = FALSE) %>%
      rename(cntry = Code, country = Name)

    ESS_5 <- left_join(ESS_5, country_list, by="cntry") %>%
      select(-cntry) %>%
      select(1:2, country, everything())

    head(ESS_5)

    ```

    \(2\) What column(s) will we use as a matching key(s) for combining the two data? Note: you can use multiple matching strategies, but I suggest we create a common matching key for both data if there are none.

    As the columns 'country' and 'year' are present in both ESS_5 and Polity V datasets, we can use combination of 'country' and 'year' columns as matching keys for combining the two datasets.

    \(3\) Join the two data (ESS_5 and Polity V). Please print the first few entries as a sanity check. Name the joined data as "ESS_Polity"

    ```{r}

    ESS_Polity <- left_join(ESS_5, Polity_V, by = c("country" = "country", "year" = "year"))

    head(ESS_Polity)

    ```

    \(4\) Save the joined data *ESS_Polity* to your local directory using the following code. We will be using this joined data to explore visualization in future challenges.

    ```{r}
    write_csv(ESS_Polity, "ESS_Polity.csv")
    ```

4.  **Describe the data structure of the newly joined data *ESS_Polity*. What is its dimension (# of rows and \# of columns)? What is its unit of observation? Compared to the original ESS_5 data, does the above data combination change the dimension and unit of observation?**

    ```{r}
    head(ESS_Polity)
    ```

    The ESS_Polity contains the combined columns of both ESS_5 and Polity V datasets. Below are the columns present in the ESS_Polity data

    ```{r}
    colnames(ESS_Polity)
    ```

    **Dimensions:**\
    Number of rows: 52458

    Number of columns: 17

    ```{r}
    cat("Dimensions of ESS_Polity: ", dim(ESS_Polity), "\n")
    ```

    **Unit of observation:**\
    The unit of observation for the ESS_Polity data is an individual's response within a specific country for a specific year. Each row in the dataset provides information about an individual ( like gender, age, education, income) and the characteristics of their country (like democracy and autocracy measures).

    **ESS_5 vs ESS_Polity:**\
    Dimension of original ESS_5 data is 52458 rows, 696 columns\
    Dimension of ESS_Polity is 52458 rows, 17 columns

    Yes, compared to ESS_5 data, the dimension of ESS_Polity is changed

    The unit of observation in the original ESS_5 data is an individual's response. In ESS_Polity, the unit of observation is an individual's response within a specific country for a specific year.

5.  **(Optional) Suppose our focus is studying regimes and governments in different countries (Polity V data). Particularly, we are interested in the relationship between the average education level in each country and the level of democracy in that country. What is the primary and foreign data in this study? How will you combine the two data?**

    In this study, the primary data is Polity V dataset as it contains the main variables of interest (level of democracy in different countries). The foreign data is the ESS_5 dataset as it provides additional information (education level) about individuals in the countries in the primary data.

    To study the relationship between the average education level in each country and the level of democracy in that country, we have to aggregate the ESS_5 data at the country level to calculate the average education level per country. Then, we join this aggregated data with the Polity V data on the 'country' column.

    ```{r}
    #Type your code here
    ESS_5_agg <- ESS_5 %>%
      group_by(country) %>%
      summarise(avg_edu = mean(edu, na.rm = TRUE))

    # Join aggregated ESS_5 data with Polity V data
    data_combined <- left_join(Polity_V, ESS_5_agg, by = "country")
    head(data_combined)
    ```

## Part 2. Writing Your Own Functions

Please use the joined data ***ESS_Polity*** in Part 1 and write a function to complete all the following tasks:

\(1\) Estimate the range, average, and standard deviation of any given numeric-type (double or integer) columns.

\(2\) Estimate the number of NAs and the number of unique values of any given column.

\(3\) Test your function with any four columns of your choice.

```{r}
#Type your code here
describe_column <- function(data, column_name) {
  if (is.numeric(data[[column_name]])) {
    cat("Column: ", column_name, "\n")
    cat("Range: ", min(data[[column_name]], na.rm = TRUE), " to ", max(data[[column_name]], na.rm = TRUE), "\n")
    cat("Average: ", mean(data[[column_name]], na.rm = TRUE), "\n")
    cat("Standard deviation: ", sd(data[[column_name]], na.rm = TRUE), "\n")
  }
  
  cat("Number of NAs: ", sum(is.na(data[[column_name]])), "\n")
  cat("Number of unique values: ", length(unique(data[[column_name]])), "\n")
}

# Testing the function with 4 columns
describe_column(ESS_Polity, "age")
describe_column(ESS_Polity, "income_10")
describe_column(ESS_Polity, "vote")
describe_column(ESS_Polity, "idno")

```

## Part 3. Practicing String Functions with Babynames

1.  **Import the babynames data:**

```{r}
babynames <- read_csv("_data/babynames.csv", show_col_types = FALSE)
head(babynames)
```

2.  **Use different stirng functions to answer the following questions:**

    \(1\) Find the longest name using [count()](https://dplyr.tidyverse.org/reference/count.html) and a string function.

    Longest name with maximum frequency is "Christopherjohn"

    ```{r}
    # Find the longest name using count()
    babynames %>%
      mutate(NameLength = str_length(Name)) %>%
      count(Name, NameLength, sort = TRUE) %>%
      arrange(desc(NameLength))

    ```

    \(2\) Use a string function to detect if the following names are present in the data:

    "Ronaldo", "Messi", "Wayne", "Clarck", "Rick", and "Morty".\
    \
    "Ronaldo", "Messi", "Wayne", "Rick", and "Morty" are present in the data.

    "Clarck" is not present in the data

    ```{r}

    names <- c("Ronaldo", "Messi", "Wayne", "Clarck", "Rick", "Morty")

    ispresent <- names %in% babynames$Name

    result <- data.frame(Name = names, Present = ispresent)

    print(result)
    ```

    \(3\) Create a column *LastName* with just one value, "LastName". Next, create another column *FullName,* by combing the strings of columns *name* and LastName, separating by a period. For example, a value in this new column should be like "Jacky.LastName".

    ```{r}
    babynames <- babynames %>%
      mutate(
        LastName = "LastName",
        FullName = paste(Name, LastName, sep = ".")
      )

    head(babynames)
    ```

    \(4\) Find all "Elizabeth" in the data and replace "Elizabeth" with "Liz".

    Assumption 1: If we want to case sensitively replace "Elizabeth" with "Liz" :

```{r}
replaced_babynames <- babynames %>%
  mutate(
    Name = str_replace_all(Name, "Elizabeth", "Liz"),
    FullName = str_replace_all(FullName, "Elizabeth", "Liz")
  )

head(replaced_babynames)
```

Assumption 2: If we want to case insensitively replace "Elizabeth" with "Liz" :

```{r}
replaced_babynames <- babynames %>%
  mutate(
    Name = str_replace_all(Name, regex("Elizabeth", ignore_case = TRUE), "Liz"),
    FullName = str_replace_all(FullName, regex("Elizabeth", ignore_case = TRUE), "Liz")
  )

head(replaced_babynames)
```

## Part 4. Clean data with import and string functions

As mentioned in the last Challenge, the original version of the survey on attitudes toward Same-Sex Marriage in Australia is raw and untidy data. You can open it in Excel and take a look at it.

The provided table includes estimates of the proportion of citizens choosing each of the four options, aggregated by Federal Electoral District, which are nested within one of 8 overarching Electoral Divisions.

In this case, we are going to identify the desired structure early in the process because clever naming of variables makes it much easier for later analysis. We will skip reading in redundant data (proportions and "totals" columns), and then can identify four potentially distinct pieces of information. Three grouping variables: *Division* (in column 1), *District* (also in column 1), and citizen *Response* (yes, no, unclear, and non-response), plus one value: aggregated response *Count*.

The ultimate goal is to use all the import and string functions we learned to generate data that looks like the data austrlia_data.csv we used in Challenge#2.

The data cleaning process should follow the following two steps. (Tips: some functions you will be using: `mutate()`,`starts_with()`, `str_detect()`, `str_starts()`) `str_ends()`, `str_detect()`, [`fill()`](https://tidyr.tidyverse.org/reference/fill.html)).

1.  Read in data, skipping unneeded columns and renaming variables.

    ```{r}

    # Reading the data
    data <- read_excel("_data/australian_marriage_law_postal_survey_2017_-_response_final.xls", sheet = "Table 2", skip = 6)

    cleaned_data <- data %>%
      # Extracting desired columns and renaming them
      select(District = 1, Yes = 2, No = 4, Illegible = 11, `No Response` = 13)

    # cleaning the data more by removing last 7 rows and empty rows
    cleaned_data <- cleaned_data %>%
      filter(!is.na(District) & !str_detect(District, regex("Total", ignore_case=TRUE) )) %>%
      filter(row_number() <= n()-7 )

    colnames(cleaned_data)

    ```

2.  Create *Division* and *District* variables using `separate()` and `fill().` You will also use string functions to help you.

    ```{r}

    cleaned_data <- cleaned_data %>%
      
      separate(District, into = c("Division", "District"), sep = "(?<=Divisions)", extra = "drop", fill = "left") %>%

      fill(Division) %>%

      mutate(District = str_trim(District)) %>%
      filter(District != "", !str_detect(District, regex("Divisions", ignore_case = TRUE)),
             !is.na(District))

    cleaned_data <- cleaned_data %>%
      select(District, everything(), -Division, Division)

    dim(cleaned_data)

    head(cleaned_data)

    ```
